
<html>
<head>
<meta charset="utf-8"/>
<title>PDDS-MLA Final Video Summary (15 Videos)</title>
<style>
  body { font-family: Arial, sans-serif; padding: 40px; max-width: 900px; margin: auto; background: #f9f9f9; }
  h2 { color: #1a73e8; }
  a { text-decoration: none; color: #1a73e8; }
  ul { margin-top: 0; margin-bottom: 20px; }
  li { margin-bottom: 5px; line-height: 1.6em; }
  p { margin-bottom: 10px; }

h2 { margin-top: 10px; }</style>
</head>
<body>
<br/><h1>ðŸ“˜ PDDS-MLA Video Timestamp Summary â€“ Full Timestamps (1â€“16)</h1>

<hr style="border: none; border-top: 2px solid #ccc; margin: 30px 0 0px 0;"/><h2>This document includes the complete timestamps and full summaries for all 15 PDDS-MLA YouTube videos, covering Regression, Classification, Clustering, Hyperparameter Tuning, NLP, and Sentiment Analysis using Azure ML Designer.</h2>
<hr style="border: none; border-top: 2px solid #ccc; margin: 30px 0 0px 0;"/><br/><h2><a href="https://youtu.be/qCF5Y04_B4o" target="_blank">1. Classification â€“ Logistic Regression</a></h2><p>Timestamps:</p><ul><li><a href="https://youtu.be/qCF5Y04_B4o?t=0" target="_blank">00:00</a> â€“ Introduction to Classification</li><li><a href="https://youtu.be/qCF5Y04_B4o?t=84" target="_blank">01:24</a> â€“ Binary vs Multiclass Classification</li><li><a href="https://youtu.be/qCF5Y04_B4o?t=172" target="_blank">02:52</a> â€“ Logistic Regression â€“ Basic Idea</li><li><a href="https://youtu.be/qCF5Y04_B4o?t=280" target="_blank">04:40</a> â€“ Sigmoid Function Explanation</li><li><a href="https://youtu.be/qCF5Y04_B4o?t=377" target="_blank">06:17</a> â€“ Logistic Regression Curve and Threshold</li><li><a href="https://youtu.be/qCF5Y04_B4o?t=462" target="_blank">07:42</a> â€“ Probabilities and Output Labels</li><li><a href="https://youtu.be/qCF5Y04_B4o?t=590" target="_blank">09:50</a> â€“ Comparing Logistic to Linear Regression</li><li><a href="https://youtu.be/qCF5Y04_B4o?t=660" target="_blank">11:00</a> â€“ Example: Diabetes Prediction</li><li><a href="https://youtu.be/qCF5Y04_B4o?t=743" target="_blank">12:23</a> â€“ Decision Boundaries</li><li><a href="https://youtu.be/qCF5Y04_B4o?t=855" target="_blank">14:15</a> â€“ Summary of Logistic Regression Concepts</li></ul><br/><p>Summary: Introduces logistic regression for binary classification using a sigmoid function. Explains prediction probabilities and decision boundaries, and demonstrates practical application in a medical dataset context.</p><hr style="border: none; border-top: 2px solid #ccc; margin: 30px 0 0px 0;"/><br/><br/><h2><a href="https://youtu.be/Qoq-wJq5-M0" target="_blank">2. Decision Tree Classifier</a></h2><p>Timestamps:</p><ul><li><a href="https://youtu.be/Qoq-wJq5-M0?t=0" target="_blank">00:00</a> â€“ Introduction to Decision Trees</li><li><a href="https://youtu.be/Qoq-wJq5-M0?t=88" target="_blank">01:28</a> â€“ Human-like Decision Modeling</li><li><a href="https://youtu.be/Qoq-wJq5-M0?t=190" target="_blank">03:10</a> â€“ Gini Impurity Definition and Logic</li><li><a href="https://youtu.be/Qoq-wJq5-M0?t=300" target="_blank">05:00</a> â€“ Weather Dataset for Play Tennis</li><li><a href="https://youtu.be/Qoq-wJq5-M0?t=405" target="_blank">06:45</a> â€“ Gini Calculation for Features</li><li><a href="https://youtu.be/Qoq-wJq5-M0?t=545" target="_blank">09:05</a> â€“ Choosing Features with Lowest Gini</li><li><a href="https://youtu.be/Qoq-wJq5-M0?t=650" target="_blank">10:50</a> â€“ Building Tree from Top Feature</li><li><a href="https://youtu.be/Qoq-wJq5-M0?t=750" target="_blank">12:30</a> â€“ Subtree for "Sunny" Branch</li><li><a href="https://youtu.be/Qoq-wJq5-M0?t=850" target="_blank">14:10</a> â€“ Final Tree and Gini-based Decisions</li><li><a href="https://youtu.be/Qoq-wJq5-M0?t=915" target="_blank">15:15</a> â€“ Tree Construction Recap</li></ul><br/><p>Summary: Demonstrates how decision trees split data using Gini impurity, and builds a complete tree using weather data to classify "Play Tennis" decisions.</p><hr style="border: none; border-top: 2px solid #ccc; margin: 30px 0 0px 0;"/><br/><br/><h2><a href="https://youtu.be/H13mVcFOET4" target="_blank">3. Classification Metrics</a></h2><p>Timestamps:</p><ul><li><a href="https://youtu.be/H13mVcFOET4?t=0" target="_blank">00:00</a> â€“ Introduction to Evaluation</li><li><a href="https://youtu.be/H13mVcFOET4?t=70" target="_blank">01:10</a> â€“ Confusion Matrix Explained</li><li><a href="https://youtu.be/H13mVcFOET4?t=138" target="_blank">02:18</a> â€“ TP, TN, FP, FN Definitions</li><li><a href="https://youtu.be/H13mVcFOET4?t=230" target="_blank">03:50</a> â€“ Accuracy Calculation</li><li><a href="https://youtu.be/H13mVcFOET4?t=305" target="_blank">05:05</a> â€“ Precision and False Positives</li><li><a href="https://youtu.be/H13mVcFOET4?t=375" target="_blank">06:15</a> â€“ Recall and False Negatives</li><li><a href="https://youtu.be/H13mVcFOET4?t=440" target="_blank">07:20</a> â€“ F1 Score Meaning and Formula</li><li><a href="https://youtu.be/H13mVcFOET4?t=510" target="_blank">08:30</a> â€“ ROC Curve and TPR/FPR</li><li><a href="https://youtu.be/H13mVcFOET4?t=590" target="_blank">09:50</a> â€“ AUC and Interpretation</li><li><a href="https://youtu.be/H13mVcFOET4?t=670" target="_blank">11:10</a> â€“ Choosing the Right Metric</li><li><a href="https://youtu.be/H13mVcFOET4?t=750" target="_blank">12:30</a> â€“ Summary of Evaluation Metrics</li></ul><br/><p>Summary: Explains each classification metric in detail, with formulas and use cases including medical diagnostics and spam detection.</p><hr style="border: none; border-top: 2px solid #ccc; margin: 30px 0 0px 0;"/><br/><br/><h2><a href="https://youtu.be/-ZWgMwaeF2s" target="_blank">4. Training Classification in Azure ML</a></h2><p>Timestamps:</p><ul><li><a href="https://youtu.be/-ZWgMwaeF2s?t=0" target="_blank">00:00</a> â€“ Overview of Designer Interface</li><li><a href="https://youtu.be/-ZWgMwaeF2s?t=95" target="_blank">01:35</a> â€“ Importing Dataset</li><li><a href="https://youtu.be/-ZWgMwaeF2s?t=160" target="_blank">02:40</a> â€“ Data Cleaning and Normalization</li><li><a href="https://youtu.be/-ZWgMwaeF2s?t=240" target="_blank">04:00</a> â€“ Splitting Dataset</li><li><a href="https://youtu.be/-ZWgMwaeF2s?t=330" target="_blank">05:30</a> â€“ Adding Untrained Classification Model</li><li><a href="https://youtu.be/-ZWgMwaeF2s?t=380" target="_blank">06:20</a> â€“ Training the Model</li><li><a href="https://youtu.be/-ZWgMwaeF2s?t=465" target="_blank">07:45</a> â€“ Scoring Predictions</li><li><a href="https://youtu.be/-ZWgMwaeF2s?t=530" target="_blank">08:50</a> â€“ Evaluating Model Performance</li><li><a href="https://youtu.be/-ZWgMwaeF2s?t=600" target="_blank">10:00</a> â€“ Reading Metrics Output</li><li><a href="https://youtu.be/-ZWgMwaeF2s?t=680" target="_blank">11:20</a> â€“ Recap of Classification Pipeline</li></ul><br/><p>Summary: Full pipeline setup for classification in Azure ML Designer including all major modules and evaluation setup.</p><hr style="border: none; border-top: 2px solid #ccc; margin: 30px 0 0px 0;"/><br/><br/><h2><a href="https://youtu.be/F-NbTEGon3g" target="_blank">5. K-Means Clustering</a></h2><p>Timestamps:</p><ul><li><a href="https://youtu.be/F-NbTEGon3g?t=0" target="_blank">00:00</a> â€“ Introduction to Clustering</li><li><a href="https://youtu.be/F-NbTEGon3g?t=80" target="_blank">01:20</a> â€“ Flower Dataset and Feature Space</li><li><a href="https://youtu.be/F-NbTEGon3g?t=180" target="_blank">03:00</a> â€“ Clustering Without Labels</li><li><a href="https://youtu.be/F-NbTEGon3g?t=265" target="_blank">04:25</a> â€“ Choosing K</li><li><a href="https://youtu.be/F-NbTEGon3g?t=345" target="_blank">05:45</a> â€“ Initial Assignment of Points</li><li><a href="https://youtu.be/F-NbTEGon3g?t=435" target="_blank">07:15</a> â€“ Updating Cluster Centroids</li><li><a href="https://youtu.be/F-NbTEGon3g?t=520" target="_blank">08:40</a> â€“ Iterative Optimization</li><li><a href="https://youtu.be/F-NbTEGon3g?t=605" target="_blank">10:05</a> â€“ Final Clusters Formed</li><li><a href="https://youtu.be/F-NbTEGon3g?t=660" target="_blank">11:00</a> â€“ Hard vs Soft Clustering</li><li><a href="https://youtu.be/F-NbTEGon3g?t=735" target="_blank">12:15</a> â€“ Student Performance Clustering Example</li></ul><br/><p>Summary: Detailed explanation of the K-Means algorithm, visualized with flower dataset and how clustering adapts with centroid movement.</p><hr style="border: none; border-top: 2px solid #ccc; margin: 30px 0 0px 0;"/><br/><br/><h2><a href="https://youtu.be/m1NShsXHLIw" target="_blank">6. Clustering in Azure ML Designer</a></h2><p>Timestamps:</p><ul><li><a href="https://youtu.be/m1NShsXHLIw?t=0" target="_blank">00:00</a> â€“ Unsupervised Workflow Overview</li><li><a href="https://youtu.be/m1NShsXHLIw?t=82" target="_blank">01:22</a> â€“ Dataset Load and Structure</li><li><a href="https://youtu.be/m1NShsXHLIw?t=155" target="_blank">02:35</a> â€“ Normalize, Clean, and Encode</li><li><a href="https://youtu.be/m1NShsXHLIw?t=240" target="_blank">04:00</a> â€“ (Optional) Data Split</li><li><a href="https://youtu.be/m1NShsXHLIw?t=312" target="_blank">05:12</a> â€“ Add and Configure K-Means Model</li><li><a href="https://youtu.be/m1NShsXHLIw?t=370" target="_blank">06:10</a> â€“ Set Number of Clusters (K)</li><li><a href="https://youtu.be/m1NShsXHLIw?t=465" target="_blank">07:45</a> â€“ Train Clustering Model</li><li><a href="https://youtu.be/m1NShsXHLIw?t=535" target="_blank">08:55</a> â€“ Assign Data to Clusters</li><li><a href="https://youtu.be/m1NShsXHLIw?t=610" target="_blank">10:10</a> â€“ Evaluate Clustering Results</li><li><a href="https://youtu.be/m1NShsXHLIw?t=690" target="_blank">11:30</a> â€“ Interpreting Cluster Output</li></ul><br/><p>Summary: How to use Azure ML Designerâ€™s clustering modules for unsupervised learning and interpret clustering metrics.</p><hr style="border: none; border-top: 2px solid #ccc; margin: 30px 0 0px 0;"/><br/><br/><h2><a href="https://youtu.be/yIYKR4sgzI8" target="_blank">7. Hyperparameter Tuning</a></h2><p>Timestamps:</p><ul><li><a href="https://youtu.be/yIYKR4sgzI8?t=0" target="_blank">00:00</a> â€“ What is Hyperparameter Tuning?</li><li><a href="https://youtu.be/yIYKR4sgzI8?t=85" target="_blank">01:25</a> â€“ Parameters vs Hyperparameters</li><li><a href="https://youtu.be/yIYKR4sgzI8?t=180" target="_blank">03:00</a> â€“ Examples: Learning Rate, K</li><li><a href="https://youtu.be/yIYKR4sgzI8?t=260" target="_blank">04:20</a> â€“ Tune Model Hyperparameters Module</li><li><a href="https://youtu.be/yIYKR4sgzI8?t=335" target="_blank">05:35</a> â€“ Grid vs Random Sampling</li><li><a href="https://youtu.be/yIYKR4sgzI8?t=410" target="_blank">06:50</a> â€“ Selecting Metric (Accuracy, RMSE)</li><li><a href="https://youtu.be/yIYKR4sgzI8?t=485" target="_blank">08:05</a> â€“ Define Search Ranges</li><li><a href="https://youtu.be/yIYKR4sgzI8?t=560" target="_blank">09:20</a> â€“ Scoring Best Model</li><li><a href="https://youtu.be/yIYKR4sgzI8?t=630" target="_blank">10:30</a> â€“ Practical Use Cases</li><li><a href="https://youtu.be/yIYKR4sgzI8?t=720" target="_blank">12:00</a> â€“ Summary</li></ul><br/><p>Summary: Explains how to tune model hyperparameters using Azure ML Designerâ€™s no-code capabilities.</p><hr style="border: none; border-top: 2px solid #ccc; margin: 30px 0 0px 0;"/><br/><br/><h2><a href="https://youtu.be/vN5cNN2-HWE" target="_blank">8. Text Classification â€“ NLP Overview</a></h2><p>Timestamps:</p><ul><li><a href="https://youtu.be/vN5cNN2-HWE?t=0" target="_blank">00:00</a> â€“ What is NLP?</li><li><a href="https://youtu.be/vN5cNN2-HWE?t=90" target="_blank">01:30</a> â€“ Structured vs Unstructured Data</li><li><a href="https://youtu.be/vN5cNN2-HWE?t=160" target="_blank">02:40</a> â€“ Use Cases of Text Classification</li><li><a href="https://youtu.be/vN5cNN2-HWE?t=230" target="_blank">03:50</a> â€“ Cleaning and Tokenization</li><li><a href="https://youtu.be/vN5cNN2-HWE?t=310" target="_blank">05:10</a> â€“ Stop Words and Lemmatization</li><li><a href="https://youtu.be/vN5cNN2-HWE?t=465" target="_blank">07:45</a> â€“ Text Representation Methods (BoW, TF-IDF)</li><li><a href="https://youtu.be/vN5cNN2-HWE?t=555" target="_blank">09:15</a> â€“ Feature Hashing &amp; Dimensionality</li><li><a href="https://youtu.be/vN5cNN2-HWE?t=670" target="_blank">11:10</a> â€“ Trade-offs in Text Features</li><li><a href="https://youtu.be/vN5cNN2-HWE?t=750" target="_blank">12:30</a> â€“ Summary</li></ul><br/><p>Summary: Introduces NLP concepts including common preprocessing and representation methods for text classification.</p><hr style="border: none; border-top: 2px solid #ccc; margin: 30px 0 0px 0;"/><br/><br/><h2><a href="https://youtu.be/BfKanl1aSG0" target="_blank">9. Text Preprocessing in Azure ML</a></h2><p>Timestamps:</p><ul><li><a href="https://youtu.be/BfKanl1aSG0?t=0" target="_blank">00:00</a> â€“ Overview of Preprocess Text Module</li><li><a href="https://youtu.be/BfKanl1aSG0?t=130" target="_blank">02:10</a> â€“ Language, Contractions, and Cleaning</li><li><a href="https://youtu.be/BfKanl1aSG0?t=195" target="_blank">03:15</a> â€“ Removing Stop Words and Numbers</li><li><a href="https://youtu.be/BfKanl1aSG0?t=265" target="_blank">04:25</a> â€“ Lemmatization and Case Normalization</li><li><a href="https://youtu.be/BfKanl1aSG0?t=330" target="_blank">05:30</a> â€“ Sentence Detection</li><li><a href="https://youtu.be/BfKanl1aSG0?t=410" target="_blank">06:50</a> â€“ Custom Regex Cleaning</li><li><a href="https://youtu.be/BfKanl1aSG0?t=490" target="_blank">08:10</a> â€“ Best Practices</li><li><a href="https://youtu.be/BfKanl1aSG0?t=570" target="_blank">09:30</a> â€“ Summary</li></ul><br/><p>Summary: Covers all Preprocess Text module settings and their impact on text quality and model input.</p><hr style="border: none; border-top: 2px solid #ccc; margin: 30px 0 0px 0;"/><br/><br/><h2><a href="https://youtu.be/Kdsp6soqA7o" target="_blank">10. Extract N-Gram Features</a></h2><p>Timestamps:</p><ul><li><a href="https://youtu.be/Kdsp6soqA7o?t=0" target="_blank">00:00</a> â€“ What Are N-Grams?</li><li><a href="https://youtu.be/Kdsp6soqA7o?t=70" target="_blank">01:10</a> â€“ Adding N-Gram Module</li><li><a href="https://youtu.be/Kdsp6soqA7o?t=140" target="_blank">02:20</a> â€“ Vocabulary and Configuration</li><li><a href="https://youtu.be/Kdsp6soqA7o?t=210" target="_blank">03:30</a> â€“ N-Gram Sizes and Filters</li><li><a href="https://youtu.be/Kdsp6soqA7o?t=285" target="_blank">04:45</a> â€“ Weighting (TF, TF-IDF)</li><li><a href="https://youtu.be/Kdsp6soqA7o?t=360" target="_blank">06:00</a> â€“ Frequency Thresholds</li><li><a href="https://youtu.be/Kdsp6soqA7o?t=435" target="_blank">07:15</a> â€“ Vector Normalization</li><li><a href="https://youtu.be/Kdsp6soqA7o?t=505" target="_blank">08:25</a> â€“ Output Format</li><li><a href="https://youtu.be/Kdsp6soqA7o?t=570" target="_blank">09:30</a> â€“ Summary</li></ul><br/><p>Summary: Shows how to extract meaningful N-Gram features for text-based models.</p><hr style="border: none; border-top: 2px solid #ccc; margin: 30px 0 0px 0;"/><br/><br/><h2><a href="https://youtu.be/vP06aMoz4v8" target="_blank">11. Feature Hashing</a></h2><p>Timestamps:</p><ul><li><a href="https://youtu.be/vP06aMoz4v8?t=0" target="_blank">00:00</a> â€“ What is Feature Hashing?</li><li><a href="https://youtu.be/vP06aMoz4v8?t=75" target="_blank">01:15</a> â€“ Use Cases and Benefits</li><li><a href="https://youtu.be/vP06aMoz4v8?t=150" target="_blank">02:30</a> â€“ Configure Hash Bit Size</li><li><a href="https://youtu.be/vP06aMoz4v8?t=200" target="_blank">03:20</a> â€“ Select Text Column and N-Gram</li><li><a href="https://youtu.be/vP06aMoz4v8?t=280" target="_blank">04:40</a> â€“ Handling Collisions</li><li><a href="https://youtu.be/vP06aMoz4v8?t=360" target="_blank">06:00</a> â€“ Efficiency vs Interpretability</li><li><a href="https://youtu.be/vP06aMoz4v8?t=440" target="_blank">07:20</a> â€“ Example Pipeline Integration</li><li><a href="https://youtu.be/vP06aMoz4v8?t=510" target="_blank">08:30</a> â€“ Summary</li></ul><br/><p>Summary: Reduces dimensionality using a hash function for efficient large-scale text representation.</p><hr style="border: none; border-top: 2px solid #ccc; margin: 30px 0 0px 0;"/><br/><br/><h2><a href="https://youtu.be/_L39rN6gz7Y" target="_blank">12. Text Classification Pipeline</a></h2><p>Timestamps:</p><ul><li><a href="https://youtu.be/_L39rN6gz7Y?t=0" target="_blank">00:00</a> â€“ Overview of Text Classification Workflow</li><li><a href="https://youtu.be/_L39rN6gz7Y?t=85" target="_blank">01:25</a> â€“ Dataset Load and Target Labels</li><li><a href="https://youtu.be/_L39rN6gz7Y?t=160" target="_blank">02:40</a> â€“ Preprocess Text Settings</li><li><a href="https://youtu.be/_L39rN6gz7Y?t=250" target="_blank">04:10</a> â€“ Feature Extraction via N-Grams or Hashing</li><li><a href="https://youtu.be/_L39rN6gz7Y?t=330" target="_blank">05:30</a> â€“ Split Data</li><li><a href="https://youtu.be/_L39rN6gz7Y?t=405" target="_blank">06:45</a> â€“ Choose and Train Classifier</li><li><a href="https://youtu.be/_L39rN6gz7Y?t=480" target="_blank">08:00</a> â€“ Score Predictions</li><li><a href="https://youtu.be/_L39rN6gz7Y?t=630" target="_blank">10:30</a> â€“ Evaluate Accuracy, F1, AUC</li><li><a href="https://youtu.be/_L39rN6gz7Y?t=705" target="_blank">11:45</a> â€“ Model Improvement Tips</li><li><a href="https://youtu.be/_L39rN6gz7Y?t=780" target="_blank">13:00</a> â€“ Summary</li></ul><br/><p>Summary: Full walkthrough of multiclass text classification from raw text to evaluation.</p><hr style="border: none; border-top: 2px solid #ccc; margin: 30px 0 0px 0;"/><br/><br/><h2><a href="https://youtu.be/wpNl-JwwplA" target="_blank">13. Sentiment Analysis</a></h2><p>Timestamps:</p><ul><li><a href="https://youtu.be/wpNl-JwwplA?t=0" target="_blank">00:00</a> â€“ What is Sentiment Analysis?</li><li><a href="https://youtu.be/wpNl-JwwplA?t=80" target="_blank">01:20</a> â€“ Dataset Description</li><li><a href="https://youtu.be/wpNl-JwwplA?t=150" target="_blank">02:30</a> â€“ Text Preprocessing Steps</li><li><a href="https://youtu.be/wpNl-JwwplA?t=245" target="_blank">04:05</a> â€“ Feature Engineering for Sentiment</li><li><a href="https://youtu.be/wpNl-JwwplA?t=345" target="_blank">05:45</a> â€“ Train/Test Split</li><li><a href="https://youtu.be/wpNl-JwwplA?t=430" target="_blank">07:10</a> â€“ Classifier Choice</li><li><a href="https://youtu.be/wpNl-JwwplA?t=505" target="_blank">08:25</a> â€“ Evaluate Performance</li><li><a href="https://youtu.be/wpNl-JwwplA?t=590" target="_blank">09:50</a> â€“ Metrics for Sentiment</li><li><a href="https://youtu.be/wpNl-JwwplA?t=660" target="_blank">11:00</a> â€“ Improving Classifier</li><li><a href="https://youtu.be/wpNl-JwwplA?t=730" target="_blank">12:10</a> â€“ Summary</li></ul><br/><p>Summary: Shows how to classify sentiments (positive, negative, neutral) from text using Azure ML Designer.</p><hr style="border: none; border-top: 2px solid #ccc; margin: 30px 0 0px 0;"/><br/><br/><h2><a href="https://youtu.be/J4Wdy0Wc_xQ" target="_blank">14. Final Review: Regression + Classification</a></h2><p>Timestamps:</p><ul><li><a href="https://youtu.be/J4Wdy0Wc_xQ?t=0" target="_blank">00:00</a> â€“ Overview of Projects</li><li><a href="https://youtu.be/J4Wdy0Wc_xQ?t=70" target="_blank">01:10</a> â€“ Regression Task: Sleep Hours</li><li><a href="https://youtu.be/J4Wdy0Wc_xQ?t=150" target="_blank">02:30</a> â€“ Features and Label Selection</li><li><a href="https://youtu.be/J4Wdy0Wc_xQ?t=230" target="_blank">03:50</a> â€“ Model Choice and Metrics</li><li><a href="https://youtu.be/J4Wdy0Wc_xQ?t=305" target="_blank">05:05</a> â€“ Classification Task: Learning Disability</li><li><a href="https://youtu.be/J4Wdy0Wc_xQ?t=375" target="_blank">06:15</a> â€“ Feature Selection</li><li><a href="https://youtu.be/J4Wdy0Wc_xQ?t=450" target="_blank">07:30</a> â€“ Evaluation Comparison</li><li><a href="https://youtu.be/J4Wdy0Wc_xQ?t=620" target="_blank">10:20</a> â€“ Documenting Results</li><li><a href="https://youtu.be/J4Wdy0Wc_xQ?t=720" target="_blank">12:00</a> â€“ Common Mistakes</li><li><a href="https://youtu.be/J4Wdy0Wc_xQ?t=795" target="_blank">13:15</a> â€“ Screenshot Checklist</li><li><a href="https://youtu.be/J4Wdy0Wc_xQ?t=885" target="_blank">14:45</a> â€“ Summary</li></ul><br/><p>Summary: Recap of Assignments 1 and 2, emphasizing proper feature selection, evaluation, and submission tips.</p><hr style="border: none; border-top: 2px solid #ccc; margin: 30px 0 0px 0;"/><br/><br/><h2><a href="https://youtu.be/sQ870aTKqiM" target="_blank">15. Final Review: Clustering + Sentiment</a></h2><p>Timestamps:</p><ul><li><a href="https://youtu.be/sQ870aTKqiM?t=0" target="_blank">00:00</a> â€“ Summary of Final Models</li><li><a href="https://youtu.be/sQ870aTKqiM?t=75" target="_blank">01:15</a> â€“ Clustering Setup and Goal</li><li><a href="https://youtu.be/sQ870aTKqiM?t=150" target="_blank">02:30</a> â€“ Features for Grouping</li><li><a href="https://youtu.be/sQ870aTKqiM?t=240" target="_blank">04:00</a> â€“ Choosing K and Evaluating</li><li><a href="https://youtu.be/sQ870aTKqiM?t=330" target="_blank">05:30</a> â€“ Sentiment Pipeline Recap</li><li><a href="https://youtu.be/sQ870aTKqiM?t=405" target="_blank">06:45</a> â€“ Preprocessing and Features</li><li><a href="https://youtu.be/sQ870aTKqiM?t=490" target="_blank">08:10</a> â€“ Model Training and Testing</li><li><a href="https://youtu.be/sQ870aTKqiM?t=565" target="_blank">09:25</a> â€“ Evaluation Metrics</li><li><a href="https://youtu.be/sQ870aTKqiM?t=645" target="_blank">10:45</a> â€“ Pipeline Troubleshooting</li><li><a href="https://youtu.be/sQ870aTKqiM?t=720" target="_blank">12:00</a> â€“ Documentation Tips</li><li><a href="https://youtu.be/sQ870aTKqiM?t=800" target="_blank">13:20</a> â€“ Screenshot Reminders</li><li><a href="https://youtu.be/sQ870aTKqiM?t=875" target="_blank">14:35</a> â€“ Final Wrap-Up</li></ul><br/><p>Summary: Final wrap-up for Assignments 3 and 4 with focus on cluster evaluation, sentiment scoring, and deliverables.</p><hr style="border: none; border-top: 2px solid #ccc; margin: 30px 0 0px 0;"/><br/>
</body>
</html>
